{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring reward funcion options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear - user score constant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an weighted average function that will assign constant weights to a multiple set of parameters and come up with a score that would be then used to rank users and assign token rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_no_userscore(parameters_weights:list,\n",
    "                        total_number_of_views:int, \n",
    "                        number_of_unique_viewers:int,\n",
    "                        number_of_prompts_created_from_content:int,\n",
    "                        views_by_user_score:dict,\n",
    "                        ):\n",
    "    '''\n",
    "    total_number_of_views: total numbers of queries that saw/used that content, \n",
    "    number_of_unique_viewers: number of unique users that saw/used the content through the queries,\n",
    "    number_of_prompts_created_from_content: number of other user's content created on top of the user content,\n",
    "    views_by_user_score: {user_score: total_number_of_views}\n",
    "    * parameters_weights: list of weights for each pameters, range should be [0, 100] and parameter_weights.sum() == 100\n",
    "                            [ w_total_views, w_unique_view, w_prompts_created, w_views_by_score] in this order\n",
    "    \n",
    "    returns: user final score for the epoch\n",
    "    '''\n",
    "    # assigning weights\n",
    "    w_total_views = parameters_weights[0]\n",
    "    w_unique_view = parameters_weights[1]\n",
    "    w_prompts_created = parameters_weights[2]\n",
    "    w_views_by_score = parameters_weights[3]\n",
    "\n",
    "    # views by score\n",
    "    # weighted average of points \n",
    "    total_scores = 0\n",
    "    score_view_products = 0\n",
    "    for score in views_by_user_score.keys():\n",
    "        score_view_products += score * views_by_user_score[score]\n",
    "        total_scores += score\n",
    "    \n",
    "    weighted_user_score = score_view_products / total_scores\n",
    "\n",
    "    final_result = (total_number_of_views * w_total_views) \\\n",
    "                    + (number_of_unique_viewers * w_unique_view) \\\n",
    "                    + (number_of_prompts_created_from_content * w_prompts_created ) + \\\n",
    "                    + (w_views_by_score * weighted_user_score)\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_test = linear_no_userscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerator:\n",
    "    def __init__(\n",
    "                self,\n",
    "                number_of_users_to_generate:int,\n",
    "                total_views_average:int,\n",
    "                total_unique_views_average:int,\n",
    "                total_prompts_created_average:int,\n",
    "                total_views_perc_extreme:float = 0.1,\n",
    "                total_views_has_extreme:bool = False,\n",
    "                total_views_compact:bool = True,\n",
    "                compact_factor:float = 0.1,\n",
    "                extreme_factor:int = 3\n",
    "                ):\n",
    "        '''\n",
    "        compact_factor: the percentage where the random values will be generate from: average_Value * +- compact_factor\n",
    "        extreme_factor: factor by what I multiply when values are not compacted to create the range from [1, averege * max I want for the metric to go]\n",
    "        '''\n",
    "        self.compact_factor = compact_factor\n",
    "        self.number_of_users_to_genereate = number_of_users_to_generate\n",
    "        self.total_views_average = total_views_average\n",
    "        self.total_unique_views_average = total_unique_views_average\n",
    "        self.total_prompts_created_average = total_prompts_created_average\n",
    "        self.total_views_has_extreme = total_views_has_extreme\n",
    "        self.total_views_compact = total_views_compact\n",
    "\n",
    "    def generate_users(self):\n",
    "        simulated_users = []\n",
    "        for x in range(self.number_of_users_to_genereate):\n",
    "            user_data = {'id': x}\n",
    "            user_data['total_views'] = self.generate_total_views()\n",
    "\n",
    "            simulated_users.append(user_data)\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    def generate_total_views(self):\n",
    "        if self.total_views_compact:\n",
    "            delta = self.total_unique_views_averagecompact_factor * self.compact_factor\n",
    "            return random.randrange(self.total_views_average - delta, self.total_views_average + delta)\n",
    "        else:\n",
    "            return  random.randrange( 1 , self.total_unique_views_average * self.extreme_factor)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing extremes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar user scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar user scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar user scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc73f21a52ccb832bf677fe91f931c0e3bb70d63042d3db79193d87a6c9b6f0c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
